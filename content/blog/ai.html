<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>A Bayesian perspective</title>
        <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

/* From extension ms-toolsai.jupyter */
/* These classnames are inherited from bootstrap, but are present in most notebook renderers */

.alert {
    width: auto;
    padding: 1em;
    margin-top: 1em;
    margin-bottom: 1em;
}
.alert > *:last-child {
    margin-bottom: 0;
}
#preview > .alert:last-child {
    /* Prevent this being set to zero by the default notebook stylesheet */
    padding-bottom: 1em;
}

.alert-success {
    /* Note there is no suitable color available, so we just copy "info" */
    background-color: var(--theme-info-background);
    color: var(--theme-info-foreground);
}
.alert-info {
    background-color: var(--theme-info-background);
    color: var(--theme-info-foreground);
}
.alert-warning {
    background-color: var(--theme-warning-background);
    color: var(--theme-warning-foreground);
}
.alert-danger {
    background-color: var(--theme-error-background);
    color: var(--theme-error-foreground);
}

/* From extension ms-toolsai.jupyter-renderers */
/*
Found that the colors of the alert boxes do not change with different themes in jlab.
Hence hardcoded them here.
*/

.alert {
    width: auto;
    padding: 1em;
    margin-top: 1em;
    margin-bottom: 1em;
	border-style: solid;
	border-width: 1px;
}
.alert > *:last-child {
    margin-bottom: 0;
}
#preview > .alert:last-child {
    /* Prevent this being set to zero by the default notebook stylesheet */
    padding-bottom: 1em;
}

.alert-success {
    background-color: rgb(200,230,201);
    color: rgb(27,94,32);
}
.alert-info {
    background-color: rgb(178,235,242);
    color: rgb(0,96,100);
}
.alert-warning {
    background-color: rgb(255,224,178);
    color: rgb(230,81,0);
}
.alert-danger {
    background-color: rgb(255,205,210);
    color: rgb(183,28,28);
}

</style>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>

    </head>
    <body class="vscode-body vscode-light">
        <hr>
<h2 id="title-the-siren-call-of-symbolic-aidate-2022-06-22t1811570100draft-true">title: &quot;The siren call of symbolic AI&quot;
date: 2022-06-22T18:11:57+01:00
draft: True</h2>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  // Autonumbering by mathjax
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });

</script>
<!-- <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
  <script>
    mermaid.initialize({ startOnLoad: true });
  </script> -->
<h2 id="a-bayesian-perspective">A Bayesian perspective</h2>
<p>Though it isn't traditionally associated with classical cognitive science and AI, phrasing the debate in the language of probability helps to locate the heart of the disagreement. Some familiarity with the notion of a probability distribution and <a href="https://ermongroup.github.io/cs228-notes/representation/undirected/">probabilistic graphical models</a> is assumed in what follows, but nothing esoteric.</p>
<!-- the linguistic notion of syntactic form is really about the sufficient statistic for meaning given form -->
<!-- concepts like systematicity are really about conditional independence of form and meaning -->
<p>To illustrate what that means, consider a classic example, the debate between Chomsky and Skinner over the nature of language understanding.</p>
<p>Skinner works from the premise that everything one can say about an agent's linguistic understanding is how it relates stimulus (data) to response (actions).</p>
 <!-- (Actually, this isn't a totally uncontroversial assumption, for reasons we'll revist at the
    end)
       (This in itself assumes a clear-cut separation of an agent from their environment, that will be worth coming back to in future.)
        -->
<p>To be concrete, let's say that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span></span></span> (short for <em>input</em>) is an acoustic signal corresponding to a natural language polar question (like &quot;Were there sharks in the ocean before there were trees on land?&quot;), and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi></mrow><annotation encoding="application/x-tex">O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span></span></span></span> (short for <em>output</em>) is a boolean choice between &quot;Yes&quot; and &quot;No&quot;. Our scientific interest is in characterizing the mapping from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi></mrow><annotation encoding="application/x-tex">O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span></span></span></span>, which describes how humans are able to answer a huge variety of such questions, previously unheard. Our engineering interest is to replicate this ability in a computer.</p>
<p>We choose these sets as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi></mrow><annotation encoding="application/x-tex">O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span></span></span></span> for the sake of a concrete example, but if you are more abstractly inclined, imagine <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span></span></span> as all sensory data received by an agent over all time until the present, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi></mrow><annotation encoding="application/x-tex">O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span></span></span></span> as all future actions.</p>
<p>In probabilistic terms, such an agent is characterized by a joint distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I, O)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span>. (It might look more familiar to talk about a conditional <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>O</mi><mi mathvariant="normal">∣</mi><mi>I</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(O|I)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mclose">)</span></span></span></span> or a prior <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mclose">)</span></span></span></span>, but both can be obtained from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I,O)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span>).</p>
<p>There's a whole range of distributions of the form <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I,O)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span>, each corresponding to a different possible model of human question answering behavior. Our goal is to specify a particular one that we think describes human behavior correctly. Note, in the spirit of Marr's levels of explanation, that it's a separate task to work out how an agent would actually approximate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>O</mi><mi mathvariant="normal">∣</mi><mi>I</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(O|I)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mclose">)</span></span></span></span> or how that approximate inference algorithm is instantiated in the brain.</p>
<p>More graphically, we write <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I,O)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span> as</p>
<pre><code class="language-mermaid">graph LR
    I((Input: Acoustic Signal)) --- O((Output  : Yes/No))
</code></pre>
<p>In the lingo, the diagram above denotes a <em>Markov random field</em> (MRF), which is a model specified by</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo><mo>∝</mo><mi>f</mi><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><mi>O</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I,O) \propto f(I)f(O)f(I,O)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span></span></p>
<p>Chomsky does not find Skinner's approach of regarding an agent in terms of its input and output objectionable, in fact he takes it as a tautology that Skinner tries to elevate to a thesis:
quote</p>
<p>His distate for it, as made famous in his review of
Skinner's
is that it obviates the importance of structure such as the syntactic representation of a sentence.</p>
<p>For context, the (very bare bones) syntactic structure of a sentence like &quot;Echo knows Narcissus&quot; might look something like this:</p>
<pre><code>           /\
          /  \
         /    \
        /     /\
       /     /  \
      /     /    \
Narcissus knows Echo

</code></pre>
<p>If you think of these trees (which particular ones determined by a grammar) as living in a space <code>Syntax</code>, one can then write the following probabilistic model:</p>
<pre><code class="language-mermaid">graph LR
    D((Acoustic Signal)) --- B((Syntax)) --- A((Yes/No))
</code></pre>
<p>Here, elements of <code>Syntax</code> are syntax trees, so that the MRF expresses the probability of a syntactic tree corresponding to an acoustic signal, and of a yes/no answer corresponding to a syntactic tree.</p>
<p>More precisely, this MRF defines a distribution</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>S</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo><mo>∝</mo><mi>f</mi><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><mi>O</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>S</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><mi>S</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I,S,O) \propto f(I)f(S)f(O)f(I,S)f(S,O)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span></span></p>
<p>and such a joint distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I,O)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span> can be recovered by marginalizing out <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>  (that is: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∫</mo><mi>S</mi></msub><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>S</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I,O) = \int_S p(I,S,O)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1608em;vertical-align:-0.3558em;"></span><span class="mop"><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0006em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1225em;"><span style="top:-2.3442em;margin-left:-0.1945em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3558em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span>)</p>
<p>In the terminology of probability, we say that we have factorized the model such that <code>Acoustic Signal</code> and <code>Yes/No</code> are <strong>conditionally independent</strong> given <code>Syntax</code>.</p>
<p>Equivalently, we say that <code>Syntax</code> is a <strong>sufficient statistic</strong> for <code>Yes/No</code> given <code>Acoustic Signal</code>.</p>
<p>What does this factorization assumption imply? The really important thing to note is that not all distributions of the form</p>
<pre><code class="language-mermaid">graph LR
    D((Acoustic Signal)) --- A((Yes/No))
</code></pre>
<p>can be expressed by marginalizing out <code>Syntax</code> from a distribution of the form:</p>
<pre><code class="language-mermaid">graph LR
    D((Acoustic Signal)) --- B((Syntax)) --- A((Yes/No))
</code></pre>
<p>As an example of a distribution which cannot, consider the distribution in which all pairs of acoustic signals with low frequencies in their spectrum and &quot;Yes&quot; have the same probability.</p>
<p>This cannot be expressed in the factored model, because syntax trees (the denizens of <code>Syntax</code>) throw away acoustic information, so there's no way of requiring this relationship between <code>Acoustic Signal</code> and <code>Yes/No</code>.</p>
<p>Note that this factorization of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I,O)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span> is not just the claim that <em>some</em> sufficient statistic like <code>Syntax</code> exists; it's always possible to choose a space <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> such that</p>
<pre><code class="language-mermaid">graph LR
    D((A)) --- B((S)) --- A((B))
</code></pre>
<p>spans the same space of possible distributions as</p>
<pre><code class="language-mermaid">graph LR
    D((A)) --- A((B))
</code></pre>
<p>e.g. by letting <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> by the Cartesian product of <code>A</code> and <code>B</code>. Rather, the substantive claim is that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> looks a certain way, in this case, that elements of <code>Syntax</code> are trees generated by a particular grammar. It is this that makes the factorization a real substantive claim.</p>
<p>At any rate, the intuition is that the factorization simplifies the problem by breaking it apart into two simpler questions: how sound and syntax relate, and how syntax and response relate. In other words, we can now put our focus into:</p>
<pre><code class="language-mermaid">graph LR
    D((Acoustic Signal)) --- B((Syntax))
</code></pre>
<p>and</p>
<pre><code class="language-mermaid">graph LR
    C((Syntax)) --- A((Yes/No))
</code></pre>
<p>The next natural step is to factorize each of these. For example:</p>
<pre><code class="language-mermaid">graph LR
    D((Acoustic Signal)) --- B((Phonology)) --- A((Syntax))
</code></pre>
<p>where the phonological representation in <code>Phonology</code> is a sequence of <em>phonemes</em>, constrained by a different set of rules to the syntax.</p>
<p>This new conditional independence assumption rules out, among others, the distribution in which all pairs of a high pitch acoustic signal and a tree with an adjective have the same probability.</p>
<p>Another factorization to make is:</p>
<pre><code class="language-mermaid">graph LR
    D((Syntax)) --- B((World)) --- A((Yes/No))
</code></pre>
<p>where <code>World</code> is the state of the world, i.e. the state of the system which produced all the sensory data the agent receives.</p>
<p>This says that the <code>Yes/No</code> answer depends on the syntax only insofar as the syntax is used to update the agent's information about the state of the world.</p>
<p>To give an example of the kinds of unreasonable distributions that the independence assumption rules out, a distribution in which all pairs of <code>Yes</code> and any tree with more than 4 nodes have the same probability, cannot now be defined. Unless, that is, precisely those trees correspond to some special state of the world, and we assume they do not.</p>
<!-- Actually, if `World` is defined in this way, then it's true that this factorization is correct: -->
<!-- rao blackwell -->
<!-- Again, the substance of this claim depends entirely on what space `World` denotes. If it is the state of the physical world, then the claim is (relatively) uncontroversial,
    since the physical world underlies any data an agent might receive, and the better the agent knows about the world, the better their decision:
        see rao blackwell, neyman pearson whatev -->
<p>Putting this all together, we have:</p>
<pre><code class="language-mermaid">graph LR
    D((Acoustics)) --- B((Phonology)) --- C((Syntax)) --- E((World)) --- A((Yes/No))
</code></pre>
<p>One more conditional independency that is evident from this graph is between <code>Phonology</code> and <code>World</code> given <code>Syntax</code>.</p>
<p>This corresponds to a well-known observation, which is that the meaning of a linguistic utterance does not depend on the way it sounds (except via the way that the sound relates to the syntax). For instance, sentences with a similar phonology like &quot;The lion desists&quot; and &quot;The ion exists&quot; may well incur very different belief updates about the state of the world.</p>
<p>Another example of a similar point is that it is never the case in languages that words that bear a phonological relationship (like rhyming) systematically also bear a semantic relationship (like denoting similar things).</p>
<p>This lack of a systematic relationship is precisely a statement about independence.</p>
<p>In particular, it's a statement about <em>conditional</em> independence. Phonology and semantics are not truly independent - &quot;fly&quot; and &quot;flying&quot; mean similar things, but <strong>conditional</strong> on syntactic (and more specifically what's called morphological structure), phonology and meaning are independent.</p>
<h2 id="generalizing-this-picture">Generalizing this picture</h2>
<p>It's obvious that an answer to a given question might depend on previous questions or statements, so really we want a picture more like:</p>
<pre><code class="language-mermaid">graph LR
    D((Acoustic Signal 1)) --- B((Phonology 1)) --- C((Syntax 1)) --- E((World)) --- A((Yes/No))

    H((Acoustic Signal 2)) --- I((Phonology 2)) --- J((Syntax 2)) --- E((World))
</code></pre>
<p>where <code>Acoustic Signal 2</code> comes after <code>Acoustic Signal 1</code>. This MRF introduces even more conditional independence assumptions. In particular, <code>World</code> is a sufficient statistic for <code>Acoustic Signal 2</code> given <code>Acoustic Signal 1</code>.</p>
<p>As a justification of why this might be a reasonable claim, note that an agent should indeed gain information about what a future acoustic signal is from a current one, but probably only in terms of the information about the world it contains.</p>
<p>For example, if the first sentence is loud, we might expect the next one to be, but only because we infer, for example, that the speaker is angry and we know that this is likely to last until the next utterance.</p>
<p>We can also incorporate vision into the picture being built up here (and other sensory data), since the answer to the question might depend on something you see, e.g. &quot;what color is the cat on your lap?&quot;</p>
<pre><code class="language-mermaid">graph LR
    X((Data)) --- D((Acoustic Signal)) --- B((Phonology)) --- C((Syntax)) --- E((World)) --- A((Yes/No))

    X --- H((Vision)) --- I((Scene Graph)) --- E((World))
</code></pre>
<p>Here, <code>Scene Graph</code> is a visual analog of <code>Syntax</code>, a sufficient statistic for visual in the form of a data structure representing the objects in the world.</p>
<p>Does the conditional independency of <code>Phonology</code> and <code>Scene Graph</code> given <code>World</code> make sense?</p>
<p>As an example, it rules out distributions in which all pairs of a phonological structure containing a /b/ phoneme, and scene graps containing a chair have the same probability, which seems sensible.</p>
<p>And it allows distributions in which precisely those phonological structures which correspond to sentences about chairs have higher probability than not of appearing with scene graphs containing chairs.</p>
<h1 id="abstraction">Abstraction</h1>
<p>The upshot is that whenever we want to abstract away from a low-level datum (like an acoustic signal or an action), we are invoking a latent variable and a conditional independence assumption.</p>
<p>For instance, it is totally natural to think of Harry Potter and the Philosopher's Stone not as a particular physical object, or even as a sequence of characters, but as a semantic object.</p>
<p>As a testament to the fact that we are comfortable with this, note that it seems uncontroversial to claim that this book in French is &quot;the same&quot; as the book in English. If a polyglot says they have read Harry Potter, we don't need to know in what language to understand what they mean.</p>
<p>And what this amounts to is the belief that there is a latent variable given which the sequence of characters of Harry Potter and the Philosopher's Stone in any two languages are conditionally independent.</p>
<pre><code class="language-mermaid">graph LR
    X((English Harry Potter)) --- D((Content)) --- B((Spanish Harry Potter))
    J((Chinese Harry Potter)) --- D --- L((Amharic Harry Potter))
</code></pre>
<p>To put it more succinctly: to believe that translation is possible is to belief that semantic content is a sufficient statistic of the various written forms.</p>
<!-- ```mermaid
graph LR
    X((Current Fashion)) --- D((Style)) --- A((Future Fashion))
``` -->
<!-- There are many other examples that could be given of factorizations of $p(I,O)$. For example, we haven't even touched on the ways in which the space of actions that an agent can perform relates to the agent's belief about the state of the world, and how this factors.  -->
<!-- ## Other examples in cognitive science


action doesn't depend on whole of world

conditional independence of future of data from past of actions:
    actually not that obvious -->
<!-- Why a joint distribution? To understand this, note that from the joint distribution, we can obtain expressions for $p(A|D)$ and $p(D)$, i.e. a description of how the agent acts given data, and what the agent believes about the data prior to receiving any. -->
<!-- As such, our scientific goal is to identify what distribution of the form $p(D,A)$ describes a natural agent, like a person. And correspondingly, an engineering goal would be to define such a distribution and draw samples from it (or its conditionals).  -->
<!-- Note that there is a distinction between the *computational specification* of the agent, namely $p(D,A)$, the *algorithmic specification* of approximate inference algorithms efficient enough (in both the computing and statistical sense) to be useful, and the *biological implementation*.  -->
<!-- Everything said so far is consistent with almost any position on the brain: it meets the rare criterion of being something both Skinner and Chomsky would agree to -->
<!-- quote attesting to this -->
<!-- But it also is saying almost nothing (not *quite* nothing though!) -->
<h2 id="returning-to-the-debate">Returning to the debate</h2>
<p>The difference between modern and classical AI has nothing to do with the presence or absence of probability in the theory, or the presence or absence of data.
footnote: for example, the picture sketched out above is entirely classical in its spirit, but entirely Bayesian in its tools.</p>
<p>Rather, it is about how the distribution that describes an agent <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I,O)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span> is factored.</p>
<p>Classical AI and cognitive science makes strong claims about the factoring, often introducing intermediate variables whose values are data types from computer science, like trees or graphs.
hence the term <em>symbolic AI</em></p>
<!-- A classic example, discussed above, is that a tree structured
    called the syntax is the sufficient statistic for
    *Syntax is the sufficient statistic for meaning given sound*. -->
<!-- The whole point of the outpouring of work in the
was to characterize this sufficient statistic, often just using people's internal judgments of what sentences sounded grammatical. -->
<p>Modern AI, along with behaviorism, makes much weaker claims.
The most radical version (in the sense of &quot;radical behaviorism&quot;) claims that there is <em>no</em> kind of factorization assumption that holds other than trivial ones.
On this perspective, the end-to-end, black box nature of modern neural AI - lack of (spurious) conditional independency - is what makes it work.</p>
<!--
for example, recall
French Harry Potter - Content - English Harry Potter

The claim is that there this sufficient statistic, the `Content` of the book, doesn't exist, or rather only exists if we let it be
    everything.
what Quine means by the indeterminacy of translation is that
there is -->
<p>And while it's possible to regard a neural net as an amortized inference algorithm for an underlying probabilistic model <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I,O)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span>, the various intermediate variables of classical AI do not appear.</p>
<p>As an example, take neural translation. One can view a complex model like a transformer, trained on pairs of English and French sentences, as learning an underlying distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>I</mi><mo separator="true">,</mo><mi>O</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(I,O)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mclose">)</span></span></span></span> (where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span></span></span> is the English sentence and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi></mrow><annotation encoding="application/x-tex">O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span></span></span></span> is the French one). However, none of the intervening variables, like <code>Phonology</code>, <code>Syntax</code> or <code>Content</code> are present explicitly, nor are these structures really possible to retrieve from the net at all.</p>
<p>Weaker claims should be preferred over stronger ones in the absence of evidence. So what does the evidence for the stronger claims of classical AI and cognitive science look like?</p>
<p>The first class of arguments are what I would call <em>appeals to poverty of stimulus</em>.</p>
<p>They go like this: if there were no conditional independencies, the distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>D</mi><mo separator="true">,</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(D,A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span> would be unlearnable or, as in the case of neural nets, would require orders of magnitude more data to learn than a human does.  (In Chomsky's words: &quot;By the age of four or five (normal) children have an almost limitless capacity to understand and produce sentences which they have never heard before.&quot;)</p>
<!-- Here, the response a Quine or a Skinner might make is this:
humans are exposed to an enormous non-stop multimodal stream of data, and what's more, they have the inductive biases of millions of years of evolution. If you think of the training cost of, say GPT3, as playing catch up with evolution, then the comparison to human learning is much less clear cut. -->
<!-- The next class of argumets are *appeals to systematicity* They go like this: the kinds of agent models that the conditional independency assumptions of classical AI rule out are exactly the kinds of models that we don't see evidenced in humans. -->
<!-- This argument is the hardest to rebut. The approach here is to press on whether this apparent systematicity is really there.

    Most tellingly, it
        is often made in terms of other proposed sufficient statistics:
        for example, systematicity in
            presupposes a ]

    But phonological structure, syntactic structure, and logical form, are all themselves posited:
        so we are

    neural networks exhibit apparent systematicity

        Tasks that computers can now perform extremely well,
        anyone with half a brain could have told you that it was obvious that no system without a symbolic representation of phonology or phonetics could possibly
            reliably recognize speech.
   -->
<!-- And certainly, the evidence for stronger claims is far from compelling -->
<p>Another set of arguments are what you could call <em>appeals to &quot;duh!&quot;</em>. They go like this: people can identify grammatical structure, visual structure (objects in a scene), and many other symbolic objects that appear in cognition. When someone tells me that my keys are in the kitchen, and I go to the kitchen, it would be bizarre to understand that behavior in terms of the acoustic signal I receive and the motor movements I make. It just seems obvious that these things are <em>there</em> and need to be worked into AI systems.</p>
<!-- "modern AI obviates something which *obviously* exists." -->
<!-- Here, it's worth bearing in my how unreliable human intuition is here.
On the other hand, while these symbolic representations certainly seem present and clear from a distance, they have a suspiciously elusive quality in practice.
    There are two possibilities:
        one is that the sheer complexity of these objects precludes
        the other is that they are at best ways of talking -->
<!-- Response:
    language and thought are full of concepts which do not translate directly into
        Just because we speak about people's personalities does not mean that a "personality" is a special variable in the -->
<p>While there are ways to respond to both these criticisms, it is futile, of course, to try to give a final word on which side is right. But to the extent that it's possible to arbitrate, it's worth doing it in a probabilistic language</p>
<div class="mermaid" markdown="0" >
graph TD
  A[Client] -->|tcp_123| B(Load Balancer)
  B -->|tcp_456| C[Server1]
  B -->|tcp_456| D[Server2]
</div>
<!-- <script async src="https://unpkg.com/mermaid@8.2.3/dist/mermaid.min.js"></script> -->
<script async src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script async mermaid.initialize({ startOnLoad: true })></script>

        <script async src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script>

    </body>
    </html>
